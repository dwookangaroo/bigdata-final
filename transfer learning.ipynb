{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b65df3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "# from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras import optimizers, initializers, regularizers, metrics\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdef4383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10960321526693127130\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4986830848\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 461723751756343274\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a457793d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import time, random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b492b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"D:/original_image/\"\n",
    "names =  [\"63building\", \"castle\",\"coex\",\"general\", \"indep_door\",\"judgement_castle\",\"lotte_tower\",\"moonlight\",\\\n",
    "                \"namsan\", \"seoulstation\",\"tapgol_park\"]\n",
    "\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1095084",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(BASE_DIR + 'train/'):\n",
    "    for name in names:\n",
    "        os.makedirs(BASE_DIR + 'train/' + name)\n",
    "        os.makedirs(BASE_DIR + 'val/' + name)\n",
    "        os.makedirs(BASE_DIR + 'test/' + name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d54e240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_folders =  [\"63building/\", \"castle/\",\"coex/\",\"general/\", \"indep_door/\",\"judgement_castle/\",\"lotte_tower/\",\"moonlight/\",\\\n",
    "                \"namsan/\", \"seoulstation/\",\"tapgol_park/\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74639fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for folder_idx, folder in enumerate(orig_folders):\n",
    "#     files = os.listdir(BASE_DIR + folder)\n",
    "#     number_of_images = len([name for name in files])\n",
    "#     n_train = int((number_of_images * 0.6) + 0.5)\n",
    "#     n_valid = int((number_of_images* 0.25) + 0.5)\n",
    "#     n_test = number_of_images - n_train - n_valid\n",
    "#     print(number_of_images, n_train, n_valid, n_test)\n",
    "#     for idx, file in enumerate(files):\n",
    "#         file_name = BASE_DIR + folder + file\n",
    "#         if idx < n_train:\n",
    "#             shutil.move(file_name, BASE_DIR + \"train/\" + names[folder_idx])\n",
    "#         elif idx < n_train + n_valid:\n",
    "#             shutil.move(file_name, BASE_DIR + \"val/\" + names[folder_idx])\n",
    "#         else:\n",
    "#             shutil.move(file_name, BASE_DIR + \"test/\" + names[folder_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd983539",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:01<00:00, 108.32it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 236.96it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 600/600 [00:02<00:00, 254.68it/s]\n",
      "  0%|▍                                                                                 | 1/200 [00:00<00:09, 20.85it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18084/619577878.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBASE_DIR\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBASE_DIR\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"test/\"\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\project-env\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   2966\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2967\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2968\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2969\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2970\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for folder_idx, folder in enumerate(org_folders):\n",
    "    sample_list = [x for x in os.listdir(BASE_DIR + folder)]\n",
    "    \n",
    "    not_train_list = random.sample(sample_list, int(len(sample_list)*0.4))\n",
    "    train_list = [x for x in sample_list if x not in not_train_list]\n",
    "    validation_list = random.sample(not_train_list, int(len(not_train_list)/2))\n",
    "    test_list = [x for x in not_train_list if x not in validation_list]\n",
    "    \n",
    "\n",
    "    for file in tqdm(test_list):\n",
    "        image = Image.open(BASE_DIR + folder + file)\n",
    "        image.save(BASE_DIR + \"test/\"+ folder + file)\n",
    "\n",
    "    for file in tqdm(validation_list):\n",
    "        image = Image.open(BASE_DIR + folder + file)\n",
    "        image.save(BASE_DIR + \"val/\"+ folder + file)\n",
    "\n",
    "    for file in tqdm(train_list):\n",
    "        image = Image.open(BASE_DIR + folder + file)\n",
    "        image.save(BASE_DIR + \"train/\"+ folder + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dce4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "valid_gen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "test_gen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "final_test_gen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "#train에 저장\n",
    "train_batches = train_gen.flow_from_directory(\n",
    "    'D:/original_image/train',\n",
    "    target_size = (240, 240),\n",
    "    class_mode = 'sparse',\n",
    "    batch_size = 2,\n",
    "    shuffle=True,\n",
    "    color_mode=\"rgb\",\n",
    "    classes=names\n",
    ")\n",
    "\n",
    "#val에 저장\n",
    "val_batches = valid_gen.flow_from_directory(\n",
    "    'D:/original_image/val',\n",
    "    target_size = (240, 240),\n",
    "    class_mode = 'sparse',\n",
    "    batch_size = 2,\n",
    "    shuffle=False,\n",
    "    color_mode=\"rgb\",\n",
    "    classes=names\n",
    ")\n",
    "\n",
    "#테스트에 저장\n",
    "test_batches = test_gen.flow_from_directory(\n",
    "    'D:/original_image/test',\n",
    "    target_size = (240, 240),\n",
    "    class_mode = 'sparse',\n",
    "    batch_size = 2,\n",
    "    shuffle=False,\n",
    "    color_mode=\"rgb\",\n",
    "    classes=names\n",
    ")\n",
    "\n",
    "# 최종 테스트\n",
    "final_test_batches = final_test_gen.flow_from_directory(\n",
    "    'D:/sub_final_test/',\n",
    "    target_size = (240, 240),\n",
    "    class_mode = 'sparse',\n",
    "    batch_size = 2,\n",
    "    shuffle=False,\n",
    "    color_mode=\"rgb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4495f782",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3,3), strides=(1,1), padding=\"valid\", activation='relu', input_shape=(240,240,3)))\n",
    "model.add(layers.MaxPool2D(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68766d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch = train_batches[0]\n",
    "print(train_batch[0].shape)\n",
    "print(train_batch[1])\n",
    "\n",
    "test_batch = test_batches[0]\n",
    "print(test_batch[0].shape)\n",
    "print(test_batch[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c17815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg 모델\n",
    "vgg_model = tf.keras.applications.vgg16.VGG16()\n",
    "print(type(vgg_model))\n",
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d06112",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "for layer in vgg_model.layers[0:-1]:\n",
    "    model.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3e304e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f230e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마지막 레이어만 train해주면됨\n",
    "#앞에 레이어 non trainable로 바꿔줌\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a87d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942f3131",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optim = keras.optimizers.Adam(lr=0.001)\n",
    "metrics = [\"accuracy\"]\n",
    "\n",
    "model.compile(optimizer=optim, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f27631",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_input = tf.keras.applications.vgg16.preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c881c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "valid_gen = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_gen = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "final_test_gen = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_batches = train_gen.flow_from_directory(\n",
    "    'D:/original_image/train',\n",
    "    target_size = (240, 240),\n",
    "    class_mode = 'sparse',\n",
    "    batch_size = 2,\n",
    "    shuffle=True,\n",
    "    color_mode=\"rgb\",\n",
    "    classes=names\n",
    ")\n",
    "\n",
    "val_batches = valid_gen.flow_from_directory(\n",
    "    'D:/original_image/val',\n",
    "    target_size = (240, 240),\n",
    "    class_mode = 'sparse',\n",
    "    batch_size = 2,\n",
    "    shuffle=False,\n",
    "    color_mode=\"rgb\",\n",
    "    classes=names\n",
    ")\n",
    "\n",
    "test_batches = test_gen.flow_from_directory(\n",
    "    'D:/original_image/test',\n",
    "    target_size = (240, 240),\n",
    "    class_mode = 'sparse',\n",
    "    batch_size = 2,\n",
    "    shuffle=False,\n",
    "    color_mode=\"rgb\",\n",
    "    classes=names\n",
    ")\n",
    "\n",
    "final_test_batches = final_test_gen.flow_from_directory(\n",
    "    'D:/sub_final_test/',\n",
    "    target_size = (240, 240),\n",
    "    class_mode = 'sparse',\n",
    "    batch_size = 2,\n",
    "    shuffle=False,\n",
    "    color_mode=\"rgb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb6de26",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5\n",
    ")\n",
    "\n",
    "history = model.fit(train_batches, validation_data=val_batches,\n",
    "         callbacks=[early_stopping],\n",
    "         epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e61b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(test_batches)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b9799f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259f43c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = load_model('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93964ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.evaluate(final_test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4b1e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datagen = ImageDataGenerator(\n",
    "#         rotation_range=2,\n",
    "#         width_shift_range=0.05,\n",
    "#         height_shift_range=0.05,\n",
    "#         shear_range=0.05,\n",
    "#         zoom_range = 0.1,\n",
    "#         horizontal_flip=False,\n",
    "#         fill_mode=\"nearest\")\n",
    "\n",
    "# folder = \"D:/sub_final_test\"\n",
    "\n",
    "# file_list = [x for x in os.listdir(folder)]\n",
    "\n",
    "# # sub_folder = \"D:/final_test/\" + \"63buliding\"\n",
    "# # sub_file_list = [x for x in os.listdir(sub_folder)]\n",
    "\n",
    "# for i in tqdm(range(len(file_list))):\n",
    "#     sub_folder = \"D:/sub_final_test/\" + file_list[i]\n",
    "#     sub_file_list = [x for x in os.listdir(sub_folder)]\n",
    "\n",
    "#     for j in range(len(sub_file_list)):\n",
    "#         image = load_img(\"D:/sub_final_test/\" + file_list[i] +\"/\" + sub_file_list[j])  # PIL 이미지\n",
    "#         x = img_to_array(image)  # (3, 300, 300) 크기의 NumPy 배열\n",
    "#         x = x.reshape((1,) + x.shape)  # (1, 3, 300, 300) 크기의 NumPy 배열\n",
    "\n",
    "#     #     아래 .flow() 함수는 임의 변환된 이미지를 배치 단위로 생성해서\n",
    "#     #     지정된 `preview/` 폴더에 저장합니다.\n",
    "#         k = 0\n",
    "#         for batch in datagen.flow(x, batch_size=5,\n",
    "#                                   save_to_dir=\"D:/sub_final_test/\" + file_list[i], save_prefix=\"super_\" + file_list[i], save_format=\"jpg\"):\n",
    "#             k += 1\n",
    "#             time.sleep(0.01)\n",
    "#             if k > 18:\n",
    "                break  # 이미지 50장을 생성하고 마칩니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff9c904",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = new_model.predict(final_test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbe667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c3487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "caltech_dir = \"D:/final_test\"\n",
    "\n",
    "\n",
    "X = []\n",
    "filenames = []\n",
    "files = glob.glob(caltech_dir+\"/*.*\")\n",
    "for i, f in enumerate(files):\n",
    "    img = Image.open(f)\n",
    "    img = img.convert(\"RGB\")\n",
    "    data = np.asarray(img)\n",
    "    filenames.append(f)\n",
    "    X.append(data)\n",
    "\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7936ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "cnt = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54e602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prediction = new_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8c57e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_names = [\"63building\", \"castle\",\"coex\",\"general\", \"indep_door\",\"judgement_castle\",\"lotte_tower\",\"moonlight\",\\\n",
    "                \"namsan\", \"seoulstation\",\"tapgol_park\"]\n",
    "\n",
    "cnt=0\n",
    "right_answer=0\n",
    "error=0\n",
    "\n",
    "# 이 비교는 그냥 파일들이 있으면 해당 파일과 비교. 카테고리와 함께 비교해서 진행하는 것은 _4 파일.\n",
    "for i in new_prediction:\n",
    "    pre_ans = i.argmax()  # 예측 레이블\n",
    "    pre_ans_str = ''\n",
    "    \n",
    "    if pre_ans == 0: pre_ans_str = \"63buliding\"\n",
    "    elif pre_ans == 1: pre_ans_str = \"castle\"\n",
    "    elif pre_ans == 2: pre_ans_str = \"coex\"\n",
    "    elif pre_ans == 3: pre_ans_str = \"general\"\n",
    "    elif pre_ans == 4: pre_ans_str = \"indep_door\"\n",
    "    elif pre_ans == 5: pre_ans_str = \"judgement_castle\"\n",
    "    elif pre_ans == 6: pre_ans_str = \"lotte_tower\"\n",
    "    elif pre_ans == 7: pre_ans_str = \"moonlight\"\n",
    "    elif pre_ans == 8: pre_ans_str = \"namsan\"\n",
    "    elif pre_ans == 9: pre_ans_str = \"seoulstation\"\n",
    "    elif pre_ans == 10: pre_ans_str = \"tapgol_park\"\n",
    "        \n",
    "        \n",
    "    else: pre_ans_str = \"what the!!\"\n",
    "        \n",
    "\n",
    "#     if i[0] >= 0.8 : print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\n",
    "#     if i[1] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"으로 추정됩니다.\")\n",
    "#     if i[2] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\n",
    "#     if i[3] >= 0.8 : print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\n",
    "#     if i[4] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"으로 추정됩니다.\")\n",
    "#     if i[5] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\n",
    "#     if i[6] >= 0.8 : print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\n",
    "#     if i[7] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"으로 추정됩니다.\")\n",
    "#     if i[8] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\n",
    "#     if i[9] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"으로 추정됩니다.\")\n",
    "#     if i[10] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\n",
    "\n",
    "    print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\n",
    "    cnt += 1\n",
    "    \n",
    "    try:        \n",
    "        if pre_ans_str in filenames[cnt].split(\"\\\\\")[1]:\n",
    "            right_answer+=1\n",
    "        else:\n",
    "            error+=1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    #얘가 레이블 [1. 0. 0.] 이런식으로 되어 있는 것을 숫자로 바꿔주는 것.\n",
    "#     즉 얘랑, 나중에 카테고리 데이터 불러와서 카테고리랑 비교를 해서 같으면 맞는거고, 아니면 틀린거로 취급하면 된다.\n",
    "#     이걸 한 것은 _4.py에.\n",
    "\n",
    "percent=round((right_answer/(right_answer + error)),4)\n",
    "print(percent)\n",
    "print(right_answer+error)\n",
    "print(len(new_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcec06e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81295904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "537231084"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model_dir = 'model'\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "tflite_model = converter.convert()\n",
    "open('converter/converted_model.tflite', 'wb').write(tflite_model)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
