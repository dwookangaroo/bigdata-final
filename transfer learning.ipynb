{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b65df3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "\n",
    "\n",
    "# from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers, initializers, regularizers, metrics\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdef4383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1876563945833553002\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4986830848\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 10891931645649765409\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a457793d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import time, random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b492b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = 'D:/original_image/'\n",
    "names = [\"63building\", \"castle\",\"general\",\"indep_door\",\"judgement_castle\",\"lotte_tower\",\"namsan\",\"tapgol_park\",\"seoulstation\",\\\n",
    "        \"coex\",\"moonlight\"]\n",
    "\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1095084",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(BASE_DIR + 'train/'):\n",
    "    for name in names:\n",
    "        os.makedirs(BASE_DIR + 'train/' + name)\n",
    "        os.makedirs(BASE_DIR + 'val/' + name)\n",
    "        os.makedirs(BASE_DIR + 'test/' + name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bddacd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_folders = [\"/63building/\", \"/castle/\",\"/general/\", \"/indep_door/\",\"/judgement_castle/\", \"/lotte_tower/\",\"/namsan/\", \"/tapgol_park/\",\\\n",
    "               \"/seoulstation/\",\"/coex/\",\"/moonlight/\"]\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd983539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0\n",
      "0 0 0 0\n",
      "0 0 0 0\n",
      "0 0 0 0\n",
      "0 0 0 0\n",
      "0 0 0 0\n",
      "0 0 0 0\n",
      "0 0 0 0\n",
      "0 0 0 0\n",
      "0 0 0 0\n",
      "0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "for folder_idx, folder in enumerate(orig_folders):\n",
    "    files = os.listdir(BASE_DIR + folder)\n",
    "    number_of_images = len([name for name in files])\n",
    "    n_train = int((number_of_images * 0.6) + 0.5)\n",
    "    n_valid = int((number_of_images* 0.25) + 0.5)\n",
    "    n_test = number_of_images - n_train - n_valid\n",
    "    print(number_of_images, n_train, n_valid, n_test)\n",
    "    for idx, file in enumerate(files):\n",
    "        file_name = BASE_DIR + folder + file\n",
    "        if idx < n_train:\n",
    "            shutil.move(file_name, BASE_DIR + \"train/\" + names[folder_idx])\n",
    "        elif idx < n_train + n_valid:\n",
    "            shutil.move(file_name, BASE_DIR + \"val/\" + names[folder_idx])\n",
    "        else:\n",
    "            shutil.move(file_name, BASE_DIR + \"test/\" + names[folder_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51dce4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6600 images belonging to 11 classes.\n",
      "Found 2750 images belonging to 11 classes.\n",
      "Found 1650 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "valid_gen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "test_gen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "#train에 저장\n",
    "train_batches = train_gen.flow_from_directory(\n",
    "    'D:/original_image/train',\n",
    "    target_size = (240, 240),\n",
    "    class_mode = 'sparse',\n",
    "    batch_size = 2,\n",
    "    shuffle=True,\n",
    "    color_mode=\"rgb\",\n",
    "    classes=names\n",
    ")\n",
    "\n",
    "#val에 저장\n",
    "val_batches = valid_gen.flow_from_directory(\n",
    "    'D:/original_image/val',\n",
    "    target_size = (240, 240),\n",
    "    class_mode = 'sparse',\n",
    "    batch_size = 2,\n",
    "    shuffle=False,\n",
    "    color_mode=\"rgb\",\n",
    "    classes=names\n",
    ")\n",
    "\n",
    "#테스트에 저장\n",
    "test_batches = valid_gen.flow_from_directory(\n",
    "    'D:/original_image/test',\n",
    "    target_size = (240, 240),\n",
    "    class_mode = 'sparse',\n",
    "    batch_size = 2,\n",
    "    shuffle=False,\n",
    "    color_mode=\"rgb\",\n",
    "    classes=names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a68766d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 240, 240, 3)\n",
      "[2. 9.]\n",
      "(2, 240, 240, 3)\n",
      "[0. 0.]\n"
     ]
    }
   ],
   "source": [
    "train_batch = train_batches[0]\n",
    "print(train_batch[0].shape)\n",
    "print(train_batch[1])\n",
    "\n",
    "test_batch = test_batches[0]\n",
    "print(test_batch[0].shape)\n",
    "print(test_batch[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8db4360",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3,3), strides=(1,1), padding=\"valid\", activation='relu', input_shape=(240,240,3)))\n",
    "model.add(layers.MaxPool2D(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75c17815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.keras.engine.training.Model'>\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# vgg 모델\n",
    "vgg_model = tf.keras.applications.vgg16.VGG16()\n",
    "print(type(vgg_model))\n",
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5d06112",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "for layer in vgg_model.layers[0:-1]:\n",
    "    model.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f3e304e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "=================================================================\n",
      "Total params: 134,260,544\n",
      "Trainable params: 134,260,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35f230e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "=================================================================\n",
      "Total params: 134,260,544\n",
      "Trainable params: 0\n",
      "Non-trainable params: 134,260,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 마지막 레이어만 train해주면됨\n",
    "#앞에 레이어 non trainable로 바꿔줌\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14a87d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "942f3131",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optim = keras.optimizers.Adam(lr=0.001)\n",
    "metrics = [\"accuracy\"]\n",
    "\n",
    "model.compile(optimizer=optim, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38f27631",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_input = tf.keras.applications.vgg16.preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52c881c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6600 images belonging to 11 classes.\n",
      "Found 2750 images belonging to 11 classes.\n",
      "Found 1650 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "valid_gen = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_gen = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_batches = train_gen.flow_from_directory(\n",
    "    'D:/original_image/train',\n",
    "    target_size = (240, 240),\n",
    "    class_mode = 'sparse',\n",
    "    batch_size = 2,\n",
    "    shuffle=True,\n",
    "    color_mode=\"rgb\",\n",
    "    classes=names\n",
    ")\n",
    "\n",
    "val_batches = valid_gen.flow_from_directory(\n",
    "    'D:/original_image/val',\n",
    "    target_size = (240, 240),\n",
    "    class_mode = 'sparse',\n",
    "    batch_size = 2,\n",
    "    shuffle=False,\n",
    "    color_mode=\"rgb\",\n",
    "    classes=names\n",
    ")\n",
    "\n",
    "test_batches = valid_gen.flow_from_directory(\n",
    "    'D:/original_image/test',\n",
    "    target_size = (240, 240),\n",
    "    class_mode = 'sparse',\n",
    "    batch_size = 2,\n",
    "    shuffle=False,\n",
    "    color_mode=\"rgb\",\n",
    "    classes=names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a93cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder = \"D:/original_image/test/moonlight\"\n",
    "# file_list = [x for x in os.listdir(folder)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4e1302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43cf427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_list=[]\n",
    "# for i in tqdm(range(len(file_list))):\n",
    "#     try:        \n",
    "#         image = Image.open(\"D:/original_image/test/moonlight/\" + file_list[i])\n",
    "#         image.save(\"D:/error_image/\" + str(i) + '.jpg')\n",
    "#         train_list.append(image)\n",
    "#     except:\n",
    "#         print('error!!',file_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1cb6de26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 3300 steps, validate for 1375 steps\n",
      "Epoch 1/15\n",
      "3300/3300 [==============================] - 99s 30ms/step - loss: 0.0064 - accuracy: 0.9994 - val_loss: 0.0284 - val_accuracy: 0.9949\n",
      "Epoch 2/15\n",
      "3300/3300 [==============================] - 100s 30ms/step - loss: 0.0096 - accuracy: 0.9976 - val_loss: 0.0360 - val_accuracy: 0.9964\n",
      "Epoch 3/15\n",
      "3300/3300 [==============================] - 101s 31ms/step - loss: 5.7590e-07 - accuracy: 1.0000 - val_loss: 0.0352 - val_accuracy: 0.9964\n",
      "Epoch 4/15\n",
      "3300/3300 [==============================] - 101s 31ms/step - loss: 3.1148e-07 - accuracy: 1.0000 - val_loss: 0.0337 - val_accuracy: 0.9964\n",
      "Epoch 5/15\n",
      "3300/3300 [==============================] - 102s 31ms/step - loss: 1.2816e-07 - accuracy: 1.0000 - val_loss: 0.0299 - val_accuracy: 0.9967\n",
      "Epoch 6/15\n",
      "3300/3300 [==============================] - 101s 31ms/step - loss: 7.0441e-09 - accuracy: 1.0000 - val_loss: 0.0285 - val_accuracy: 0.9971\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5\n",
    ")\n",
    "\n",
    "history = model.fit(train_batches, validation_data=val_batches,\n",
    "         callbacks=[early_stopping],\n",
    "         epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "95e61b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "825/825 [==============================] - 19s 23ms/step - loss: 5.3765e-04 - accuracy: 0.9994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.99939394"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, acc = model.evaluate(test_batches)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d4b9799f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "259f43c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = load_model('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fe6044f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "825/825 [==============================] - 19s 23ms/step - loss: 5.3765e-04 - accuracy: 0.9994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0005376493907373391, 0.99939394]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.evaluate(test_batches)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
